{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 88842,
          "status": "ok",
          "timestamp": 1752087601268,
          "user": {
            "displayName": "MD.RAFIUL BISWAS",
            "userId": "15801257354586832441"
          },
          "user_tz": -180
        },
        "id": "9_KVo-Jw6Ler",
        "outputId": "6631d835-084d-4e31-aa9d-bc2a773f8fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[?25l     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m153.6/803.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m798.7/803.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=b5b0196f0aee62fe11a6ee9734af952f615ebe05299d0a6bb18b7b921f7e0591\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/d2/9a/801b5cc5b2a1af2e280089b71c326711a682fc1d50ea29d0ed\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20250625\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5658,
          "status": "ok",
          "timestamp": 1752087606930,
          "user": {
            "displayName": "MD.RAFIUL BISWAS",
            "userId": "15801257354586832441"
          },
          "user_tz": -180
        },
        "id": "D8VGLrv0i6nQ",
        "outputId": "bfe0dc3e-f59b-4475-8b27-a2b0cead55df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets==3.5.0\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.70.15)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.5.0)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.33.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.5.0) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.5.0) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.5.0) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 fsspec-2024.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets==3.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irTITEG98gR2"
      },
      "outputs": [],
      "source": [
        "# API Keys (add your keys here)\n",
        "FANAR_API_KEY = \"token\"  # Your existing FANAR key\n",
        "HUGGINGFACE_TOKEN = \"hf_token\"      # Get from https://huggingface.co/settings/tokens\n",
        "OPENROUTER_API_KEY = \"token\"       # Optional: from https://openrouter.ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "a281015c849941dd95d151cf219d0bb8",
            "fe90bb0f6a874320b5bc8d349235943d"
          ]
        },
        "executionInfo": {
          "elapsed": 917,
          "status": "ok",
          "timestamp": 1752087607855,
          "user": {
            "displayName": "MD.RAFIUL BISWAS",
            "userId": "15801257354586832441"
          },
          "user_tz": -180
        },
        "id": "iWj4vckz8ihF",
        "outputId": "2ccc071d-f042-4041-c13a-f77f406d66d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a281015c849941dd95d151cf219d0bb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login(new_session=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "e802aded95704260b494633ff3fba5e7",
            "effa9727e8a74aea8004a8f15a47ad68",
            "a4e8d7c099624b47869211222dc83d34",
            "9d2c17dae395432193a9c8420e453328",
            "76d4d7f85d254d4f8fbf0d3a598f80c7",
            "17d6613c875f453687e0f0e641f0aedb",
            "f7811d02248444f9834ade4e77410f02",
            "2727bcd4552e405d81454c59c1b78be7",
            "c6e2cf2cc3ec47d897bba1178889c6dc",
            "01166807dd654517beb5c32f0a34d00b",
            "9eca760780be4bc1a091728833580cbc",
            "b0e400b80dd144f4b721579a31d0cb41",
            "35a2740a83dd434386e4b6859c2efd09",
            "db2cbc1a008c4905bb4c4ebe2e3eb0b4",
            "307b0de117cf40019b6be162c9e9ee4b",
            "d61c975ea0b242deb89442d87c402bd1",
            "c7bf7b7011b34e9b9c1d6976be0d1b8e",
            "394d1c7ee7f54950b86fab3aa5524a2c",
            "895a2767a7fd4b3f832e3e0af182a5b2",
            "e934421f15a54ee6b3c1592369a76f2f",
            "5a8f0b2e7ff24855b6f6b8b62e71261c",
            "28718c8c2190463e8a995ccb302746ee",
            "174ae3f6cbbc44bf9e55f502e9e52af5",
            "9085d2679f534d818ff93d8af2184335",
            "861b51b5e63f492c95b91fac5a0baa5f",
            "7ab98977d6cb44e8b327f9525924c947",
            "ebdd0e8ef4b44c9995cd08fb0c8d7680",
            "7c41178b59d041d5b4c1af21268e6660",
            "3bb64a489d3a48969d51a217c6ba90c5",
            "805c5b702ce04fe7b76c5cf22c336541",
            "6e9c1406d389436c81e8258cad07fc0b",
            "34b4d08304ce4dd190205eb8d1036d78",
            "2a9fa62ab4f8437381ef3a798f1d81d3",
            "c2322fee64ab48eaba51514716a85ac7",
            "bf30be5ed9ed4a8f84f2841272513c0d",
            "d3699138adc2460ebb02b11bfe9a282a",
            "22325e5ad09b43da9841d43cd82b8180",
            "112434fcbaed49f29aae9cfe00101fee",
            "94ae6892ad114bab91606785db809431",
            "5f3c0bdc2c1d46ee821f17bec3f03ee9",
            "b847013e01f44fd4a287895105a20ae4",
            "0f77fe981d2a4bb4af0a9540f1f7a0d2",
            "cccff98c61d64301bdde82460d81f939",
            "90af04f083224a2e8261a1b62f0dea64",
            "baf3e7f51b4548a8986e344ea5ebb4f7",
            "9238587e466f4ae394c7e0ea8f5f28e3",
            "27245741007f4484ab03b441719c312b",
            "bffda921358d49aeadf438416bc022fb",
            "ef2994285202429fa9177dd3f4adea06",
            "b89265ccd50f43b6bc8a9986e1ffa264",
            "6f2ad9bd3da64d8b8754847d35b04658",
            "9e13baba80c146b09baf027dee15a7e4",
            "974610123af843b9a815d94fd511fea2",
            "05cb649134fd499fb76445064fa71489",
            "19b60fbfbac74a31b2b6bf7fe0321c27",
            "6b2b4a60f8334354a4ee4f2b34575125",
            "1b9be504ceae48509b37e5751ac97bac",
            "beaabe1a3e6f44c4adb8c302a8b5cf9f",
            "357bf31d09c143deb1477b804753cd28",
            "dcb70aad0aa24754b305d12fd6a39403",
            "0ca42732af2e4d4f9e8917f6f763687f",
            "cd0b80c33c5c4ce39a2d2694db89c94d",
            "dbabf18648fc4ee8a74f71ba34e4fefd",
            "b43638d2277242b8bf1257114f0e22bc",
            "3084d79bb2264126a604b3c36b4eef90",
            "d28d941076a341d1a0237f03e51c2f3e",
            "33dc8d8d271042f18605e0a5a4b768cf",
            "585d95f25e4943c086b19786f0e9c255",
            "99e97f05a8f048d6bfe28686761d3855",
            "10c231965bd3400ba59b3c0b4c32b52f",
            "87cf4f5e2fc0402ea4debd131f6186ed",
            "370c8a8e9fa740e19abca6ed17cc12aa",
            "ddb2b0a477be4ca5a130cae4b4b58495",
            "43a818573a4448408f46c0e50021b32c",
            "242cd5af9774467d8e5cd8935b8561eb",
            "b85d9033fb424d98b1d17059de797d21",
            "ece8cc3669594a1cbe5d6826dcf90e3c",
            "c55bd10433744d6999ac42ebe88f531c",
            "2ff5891b4c8542ef950326390df9590e",
            "c778201c88d649bfb0ef84ecbe295317",
            "fbf1d967ae10447a85d89dfd99e1861c",
            "37b17a4635594996ac7dbe894801b3bb",
            "ec15dbe8419547f39c44c4324a2dcadb",
            "5b8d1b69c5174c41b9ce2001b6e0be96",
            "b5f4d63b3f29428b8a11b3be869febeb",
            "dbcbfa873ef64be198b5e970a2a3e387",
            "4daf627c7625474a9b20c70f85b40e3c",
            "34c365ec33074a1f905a299780e2e682",
            "fc20c37512e249fbb03b060a7c9d92b6",
            "489ef3ae7b8146fe9fe1707459b13f65",
            "e62a5a263ca6473cb1fbb39767d9721c",
            "b3c5ab9848af4e8cad4af0cc3ff7c34f",
            "61c670c33ce84150b5549d714a47a0fb",
            "c45a10d27be3433ca7ccb7c20d9fc116",
            "a582b87957f1401f80bb7dacb974c0c8",
            "e9f7531b1196412295efab801e31b660",
            "96a6492aad7d40929431fc0a69a3a3f0",
            "4ba4e6528b8b4eaf96d6f67df9ab418a",
            "5fc76914e2da4ad7a48ab1e81ba08adb",
            "c3b16b8c995345f0b184685b4c776f6c",
            "9ff15149bf3c4c629d87898ae41373d5",
            "0c8f9b0ed81444339091a48093178291",
            "e7cf38b6152b4b98a20bd730bca88f54",
            "f112c6cd85334955b671c24269cd8de8",
            "f5b0d060436d4520aa2e36bcb550c194",
            "e4d7b2a33b0745bebb28f51b38ccc0f9",
            "73130c000627478990bd3107ffb5cf58",
            "87933d934c994ae78bd6b49dd852c344",
            "0e077b4c353a46feacf89fe2fd1602a1",
            "b31b91693761454e856acbc811bb0e28",
            "4548cf0cac134e4c837f389eb8a49211",
            "758c007824c64512becc8c59defa8dff",
            "0036c03ef5804d1c89081f4f85f4b6ca",
            "f57d5eef44fc4e88987fe114c3f56ff9",
            "9a481012c87b464fbae8a96ee387e3c2",
            "ad73fb129dbb44799636231196d00cdd",
            "9aa09c9f6b8543e9b4500ddcecea7ff5",
            "c007988c2283435cb47a3c51bd0a9543",
            "90a9108284104a739bb74a03618e3c58",
            "2b19dbca5d334a7b8bcf51d0f8974b93",
            "17bdb59a83de46be99472d5e91f3ab40"
          ]
        },
        "executionInfo": {
          "elapsed": 37756,
          "status": "ok",
          "timestamp": 1752087656280,
          "user": {
            "displayName": "MD.RAFIUL BISWAS",
            "userId": "15801257354586832441"
          },
          "user_tz": -180
        },
        "id": "pX01WhUc8kCz",
        "outputId": "fda5b1f0-2945-4e8c-8cca-87699683c189"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e802aded95704260b494633ff3fba5e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0e400b80dd144f4b721579a31d0cb41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00004.parquet:   0%|          | 0.00/456M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "174ae3f6cbbc44bf9e55f502e9e52af5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00001-of-00004.parquet:   0%|          | 0.00/416M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2322fee64ab48eaba51514716a85ac7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00002-of-00004.parquet:   0%|          | 0.00/469M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "baf3e7f51b4548a8986e344ea5ebb4f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00003-of-00004.parquet:   0%|          | 0.00/459M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b2b4a60f8334354a4ee4f2b34575125",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation-00000-of-00004.parquet:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33dc8d8d271042f18605e0a5a4b768cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation-00001-of-00004.parquet:   0%|          | 0.00/402M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c55bd10433744d6999ac42ebe88f531c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation-00002-of-00004.parquet:   0%|          | 0.00/462M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc20c37512e249fbb03b060a7c9d92b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation-00003-of-00004.parquet:   0%|          | 0.00/448M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3b16b8c995345f0b184685b4c776f6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/12900 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4548cf0cac134e4c837f389eb8a49211",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/12700 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "countries = ['Algeria', 'Egypt', 'Jordan', 'Mauritania', 'Morocco', 'Palestine', 'UAE', 'Yemen']\n",
        "\n",
        "ds = load_dataset(\"UBC-NLP/NADI2025_subtask2_SLID\")\n",
        "ds.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 10,
          "status": "ok",
          "timestamp": 1752087656303,
          "user": {
            "displayName": "MD.RAFIUL BISWAS",
            "userId": "15801257354586832441"
          },
          "user_tz": -180
        },
        "id": "v0AVCOEc8oVR",
        "outputId": "1c946079-f7f3-4c0a-acf7-29bcfcae0a66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['ID', 'audio', 'country'],\n",
              "        num_rows: 12900\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['ID', 'audio', 'country'],\n",
              "        num_rows: 12700\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLxkgdk-Ssav"
      },
      "outputs": [],
      "source": [
        "# Helper function to check trainable parameters (same as baseline)\n",
        "def print_trainable_parameters(model):\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Leg7Q0q6TCQY"
      },
      "outputs": [],
      "source": [
        "def write_logits(o, filename):\n",
        "  with open(filename, \"a\") as fp:\n",
        "    for i in o:\n",
        "      l = \"\"\n",
        "      for j in i:\n",
        "        l += str(j.item()) + \"\\t\"\n",
        "      fp.write(str.strip(l)+\"\\n\")\n",
        "\n",
        "def write_preds(o, filename):\n",
        "  with open(filename, \"a\") as fp:\n",
        "    for i in o:\n",
        "      fp.write(str.strip(str(i.item()))+\"\\n\")\n",
        "\n",
        "def submission_writer(model, loader):\n",
        "  for batch in tqdm(loader):\n",
        "      wavs, _, labels = batch\n",
        "\n",
        "      with torch.no_grad():\n",
        "        wavs = wavs.to(device)\n",
        "        o = model(wavs.transpose(1,0))\n",
        "        write_logits(o[0].to('cpu'), 'logits.tsv')\n",
        "        write_preds(o[2].to('cpu'), 'predictions.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2Z-LUYr-uMv"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "\n",
        "labels2id = {key:id for id, key in enumerate(countries)}\n",
        "id2labels = {id:key for key,id in labels2id.items()}\n",
        "\n",
        "def col_fun(samples):\n",
        "\n",
        "  arrays = [sample['audio']['array'] for sample in samples]\n",
        "  lengths = list(map(lambda x: len(x), arrays))\n",
        "  countries = torch.tensor([labels2id[sample['country']] for sample in samples])\n",
        "  packed = pad_sequence(arrays)\n",
        "\n",
        "  return packed, lengths, countries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2cnsRk6fE9Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "#Calculate log likelihood ratios\n",
        "def llr(logits):\n",
        "  classes = logits.shape[1]\n",
        "  l2 = logits.unsqueeze(dim=1)\n",
        "\n",
        "  l = logits.unsqueeze(dim=1)\n",
        "  l = l.repeat(1,8,1)\n",
        "  l2 = l2.repeat(1,8,1)\n",
        "  l2 = l2.permute((0,2,1))\n",
        "  dif = l-l2\n",
        "  e = torch.exp(dif)\n",
        "  for i in range(len(e)):\n",
        "    e[i].fill_diagonal_(0)\n",
        "  return -torch.log(torch.sum(e,dim=-1)/ (classes-1))\n",
        "\n",
        "\n",
        "\n",
        "#Actual Cost Function from the NIST Speech Recognition Evaluation tool package\n",
        "\n",
        "def compute_actual_cost(scores, labels, p_target, c_miss=1, c_fa=1):\n",
        "    beta = c_fa * (1 - p_target) / (c_miss * p_target)\n",
        "    decisions = (scores >= np.log(beta)).astype('i')\n",
        "    num_targets = np.sum(labels)\n",
        "    fp = np.sum(decisions * (1 - labels))\n",
        "    num_nontargets = np.sum(1 - labels)\n",
        "    fn = np.sum((1 - decisions) * labels)\n",
        "    fpr = fp / num_nontargets if num_nontargets > 0 else np.nan\n",
        "    fnr = fn / num_targets if num_targets > 0 else np.nan\n",
        "    return fnr + beta * fpr, fpr, fnr\n",
        "\n",
        "def compute_ave_cost(logits, labels, num_l = 8):\n",
        "  llratio = llr(logits)\n",
        "  llratio = llratio.numpy()\n",
        "  labels = labels.numpy()\n",
        "  order = labels.argsort()\n",
        "  labels.sort()\n",
        "  llratio = llratio[order]\n",
        "  indices = np.where(labels[:-1] != labels[1:])[0]\n",
        "  indices = np.append(indices, [-1])\n",
        "  one_hot = np.eye(8)[labels]\n",
        "  fprs = []\n",
        "  fnrs = []\n",
        "  last = 0\n",
        "  for i in indices:\n",
        "    _, fpr, fnr = compute_actual_cost(llratio[last:i], one_hot[last:i], 0.5)\n",
        "    fprs.append(fpr)\n",
        "    fnrs.append(fnr)\n",
        "    last = i\n",
        "  fpr = sum(fprs)/num_l\n",
        "  fnr = sum(fnrs)/num_l\n",
        "  cost = fpr+fnr\n",
        "  return cost, fpr, fnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn8grMs7eh00"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim.lr_scheduler import LinearLR, SequentialLR, ExponentialLR, ConstantLR\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "import whisper\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.notebook import tqdm\n",
        "import librosa\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class WhisperARBERTDialectClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined Whisper ASR + ARBERT/MARBERT text classification pipeline\n",
        "    Following efficient transfer learning approach like SpeechBrain\n",
        "    \"\"\"\n",
        "    def __init__(self, whisper_model_name=\"large-v3\", text_model_name=\"UBC-NLP/MARBERT\", num_classes=8):\n",
        "        super().__init__()\n",
        "\n",
        "        # Load Whisper model for ASR\n",
        "        print(f\"Loading Whisper model: {whisper_model_name}\")\n",
        "        self.whisper_model = whisper.load_model(whisper_model_name)\n",
        "\n",
        "        # Load ARBERT/MARBERT model for text classification\n",
        "        print(f\"Loading text model: {text_model_name}\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(text_model_name)\n",
        "\n",
        "        # Load the base model without classification head (like SpeechBrain)\n",
        "        self.text_encoder = AutoModel.from_pretrained(text_model_name)\n",
        "\n",
        "        # Freeze Whisper model\n",
        "        for param in self.whisper_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Freeze text encoder (like SpeechBrain approach)\n",
        "        for param in self.text_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Replace classifier layer (similar to SpeechBrain approach)\n",
        "        # Get hidden size from the text encoder\n",
        "        hidden_size = self.text_encoder.config.hidden_size\n",
        "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "        print(f\"Created new classifier: {hidden_size} -> {num_classes}\")\n",
        "        print(f\"Frozen Whisper parameters: {sum(p.numel() for p in self.whisper_model.parameters()):,}\")\n",
        "        print(f\"Frozen text encoder parameters: {sum(p.numel() for p in self.text_encoder.parameters()):,}\")\n",
        "        print(f\"Trainable classifier parameters: {sum(p.numel() for p in self.classifier.parameters()):,}\")\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def transcribe_audio(self, audio_tensor):\n",
        "        \"\"\"\n",
        "        Transcribe audio using Whisper\n",
        "        \"\"\"\n",
        "        # Convert tensor to numpy and ensure proper format\n",
        "        if isinstance(audio_tensor, torch.Tensor):\n",
        "            audio_numpy = audio_tensor.cpu().numpy()\n",
        "        else:\n",
        "            audio_numpy = audio_tensor\n",
        "\n",
        "        # Whisper expects audio in specific format\n",
        "        if audio_numpy.ndim > 1:\n",
        "            audio_numpy = audio_numpy.squeeze()\n",
        "\n",
        "        # Transcribe with Whisper\n",
        "        result = self.whisper_model.transcribe(\n",
        "          audio_numpy,\n",
        "          language='ar',\n",
        "          task='transcribe',\n",
        "          beam_size=1,    # Higher quality (default for v3)\n",
        "          best_of=1,      # Better results\n",
        "          temperature=0   # Deterministic\n",
        "        )\n",
        "\n",
        "        return result['text']\n",
        "\n",
        "    def classify_text(self, text):\n",
        "        \"\"\"\n",
        "        Classify text using frozen ARBERT/MARBERT encoder + new classifier\n",
        "        \"\"\"\n",
        "        # Tokenize text\n",
        "        inputs = self.tokenizer(\n",
        "            text,\n",
        "            return_tensors='pt',\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "        # Move to device\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "        # Get embeddings from frozen text encoder\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = self.text_encoder(**inputs)\n",
        "            # Use [CLS] token embedding (first token)\n",
        "            embeddings = encoder_outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Pass through trainable classifier\n",
        "        logits = self.classifier(embeddings)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def forward(self, audio_batch, training=False):\n",
        "        \"\"\"\n",
        "        Forward pass: Audio -> Whisper -> Text -> Frozen ARBERT -> New Classifier -> Logits\n",
        "        \"\"\"\n",
        "        batch_size = audio_batch.shape[0]\n",
        "        all_logits = []\n",
        "\n",
        "        # During training, we need to handle gradients properly\n",
        "        if training:\n",
        "            # Pre-transcribe all audio to avoid gradient issues\n",
        "            transcripts = []\n",
        "            for i in range(batch_size):\n",
        "                audio_sample = audio_batch[i].cpu().numpy()\n",
        "                try:\n",
        "                    transcript = self.transcribe_audio(audio_sample)\n",
        "                    if not transcript.strip():\n",
        "                        transcript = \"\u0644\u0627 \u064a\u0648\u062c\u062f \u0646\u0635\"  # \"No text\" in Arabic\n",
        "                    transcripts.append(transcript)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error transcribing audio {i}: {e}\")\n",
        "                    transcripts.append(\"\u0644\u0627 \u064a\u0648\u062c\u062f \u0646\u0635\")\n",
        "\n",
        "            # Batch process all transcripts\n",
        "            if transcripts:\n",
        "                inputs = self.tokenizer(\n",
        "                    transcripts,\n",
        "                    return_tensors='pt',\n",
        "                    truncation=True,\n",
        "                    padding=True,\n",
        "                    max_length=512\n",
        "                )\n",
        "                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "                # Get embeddings from frozen encoder\n",
        "                with torch.no_grad():\n",
        "                    encoder_outputs = self.text_encoder(**inputs)\n",
        "                    embeddings = encoder_outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "                # Pass through trainable classifier\n",
        "                final_logits = self.classifier(embeddings)\n",
        "            else:\n",
        "                final_logits = torch.randn(batch_size, 8).to(self.device)\n",
        "\n",
        "        else:\n",
        "            # Inference mode - process individually\n",
        "            for i in range(batch_size):\n",
        "                audio_sample = audio_batch[i].cpu().numpy()\n",
        "\n",
        "                try:\n",
        "                    # Transcribe audio\n",
        "                    transcript = self.transcribe_audio(audio_sample)\n",
        "\n",
        "                    # Handle empty transcriptions\n",
        "                    if not transcript.strip():\n",
        "                        transcript = \"\u0644\u0627 \u064a\u0648\u062c\u062f \u0646\u0635\"  # \"No text\" in Arabic\n",
        "\n",
        "                    # Classify text\n",
        "                    logits = self.classify_text(transcript)\n",
        "                    all_logits.append(logits)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing audio sample {i}: {e}\")\n",
        "                    # Return random logits as fallback\n",
        "                    fallback_logits = torch.randn(1, 8).to(self.device)\n",
        "                    all_logits.append(fallback_logits)\n",
        "\n",
        "            # Concatenate all logits\n",
        "            final_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "        # Get predictions\n",
        "        predictions = torch.argmax(final_logits, dim=1)\n",
        "\n",
        "        # Get max scores (for compatibility with baseline)\n",
        "        max_scores = torch.max(final_logits, dim=1)[0]\n",
        "\n",
        "        # Return in same format as baseline: (logits, max_scores, predictions, country_names)\n",
        "        country_names = [id2labels[pred.item()] for pred in predictions]\n",
        "\n",
        "        return final_logits, max_scores, predictions, country_names\n",
        "\n",
        "# Initialize the new model\n",
        "def create_whisper_arbert_model():\n",
        "    \"\"\"\n",
        "    Create and initialize the Whisper + ARBERT model\n",
        "    \"\"\"\n",
        "    model = WhisperARBERTDialectClassifier(\n",
        "        whisper_model_name=\"large-v3\",  # Using Whisper Large v3\n",
        "        text_model_name=\"UBC-NLP/MARBERT\",  # or \"UBC-NLP/ARBERT\"\n",
        "        num_classes=8\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Modified collate function to handle audio preprocessing\n",
        "def col_fun_whisper(samples):\n",
        "    \"\"\"\n",
        "    Collate function for Whisper + ARBERT model\n",
        "    \"\"\"\n",
        "    arrays = []\n",
        "    countries = []\n",
        "\n",
        "    for sample in samples:\n",
        "        # Get audio array\n",
        "        audio_array = sample['audio']['array']\n",
        "\n",
        "        # Ensure audio is in correct format for Whisper (16kHz, mono)\n",
        "        if isinstance(audio_array, torch.Tensor):\n",
        "            audio_array = audio_array.numpy()\n",
        "\n",
        "        # Pad or truncate to reasonable length (30 seconds max for Whisper)\n",
        "        max_length = 16000 * 30  # 30 seconds at 16kHz\n",
        "        if len(audio_array) > max_length:\n",
        "            audio_array = audio_array[:max_length]\n",
        "\n",
        "        arrays.append(torch.from_numpy(audio_array).float())\n",
        "        countries.append(labels2id[sample['country']])\n",
        "\n",
        "    # Pad sequences to same length\n",
        "    lengths = [len(arr) for arr in arrays]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_arrays = []\n",
        "    for arr in arrays:\n",
        "        if len(arr) < max_len:\n",
        "            padded = torch.nn.functional.pad(arr, (0, max_len - len(arr)))\n",
        "        else:\n",
        "            padded = arr\n",
        "        padded_arrays.append(padded)\n",
        "\n",
        "    packed = torch.stack(padded_arrays)\n",
        "    countries_tensor = torch.tensor(countries)\n",
        "\n",
        "    return packed, lengths, countries_tensor\n",
        "\n",
        "# Modified evaluation loop for the new model\n",
        "def eval_loop_whisper(model, loader):\n",
        "    \"\"\"\n",
        "    Evaluation loop for Whisper + ARBERT model\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    tp = 0\n",
        "    n = 0\n",
        "    logits_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader):\n",
        "            wavs, _, labels = batch\n",
        "\n",
        "            try:\n",
        "                # Forward pass in evaluation mode\n",
        "                o = model(wavs, training=False)\n",
        "\n",
        "                # Collect results\n",
        "                logits_list.append(o[0].cpu())\n",
        "                labels_list.append(labels.cpu())\n",
        "\n",
        "                # Calculate accuracy\n",
        "                preds = o[2].cpu()\n",
        "                tp += accuracy_score(labels, preds, normalize=False)\n",
        "                n += len(labels)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in evaluation: {e}\")\n",
        "                # Skip this batch\n",
        "                continue\n",
        "\n",
        "    if len(logits_list) == 0:\n",
        "        print(\"No successful predictions during evaluation!\")\n",
        "        return 0.0, 1.0, 1.0, 1.0\n",
        "\n",
        "    # Concatenate results\n",
        "    logits = torch.concat(logits_list, dim=0)\n",
        "    labels = torch.concat(labels_list, dim=0)\n",
        "\n",
        "    # Calculate cost metrics\n",
        "    cost, fpr, fnr = compute_ave_cost(logits, labels)\n",
        "\n",
        "    return tp/n * 100, cost, fpr, fnr\n",
        "\n",
        "# Modified training loop\n",
        "def train_whisper_arbert_model(model, trainloader, valloader, device):\n",
        "    \"\"\"\n",
        "    Training loop for Whisper + ARBERT model\n",
        "    Following SpeechBrain approach - only train the classifier\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.device = device\n",
        "\n",
        "    # Only train the new classifier layer (like SpeechBrain approach)\n",
        "    optimizer = AdamW(model.classifier.parameters(), lr=2e-5)\n",
        "\n",
        "    max_steps = 3000  # Reduced since we're training much fewer parameters\n",
        "    logging_steps = 100\n",
        "    val_steps = 500\n",
        "\n",
        "    # Simple learning rate schedule\n",
        "    scheduler = LinearLR(optimizer, start_factor=0.1, end_factor=1.0, total_iters=300)\n",
        "\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "\n",
        "    avg_loss = 0\n",
        "    step = 1\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    print_trainable_parameters(model)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    while step <= max_steps:\n",
        "\n",
        "        for batch in tqdm(trainloader, desc=f\"Training Step {step}\"):\n",
        "            if step > max_steps:\n",
        "                break\n",
        "\n",
        "            wavs, _, labels = batch\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            try:\n",
        "                # Forward pass with training flag\n",
        "                o = model(wavs, training=True)\n",
        "                logits = o[0]\n",
        "\n",
        "                # Calculate loss\n",
        "                loss = loss_fn(logits, labels)\n",
        "                loss.backward()\n",
        "\n",
        "                optimizer.step()\n",
        "                if step <= 300:\n",
        "                    scheduler.step()\n",
        "\n",
        "                avg_loss += loss.item()\n",
        "\n",
        "                # Logging\n",
        "                if step % logging_steps == 0:\n",
        "                    print(f\"Step {step}: Loss {avg_loss/logging_steps:.4f}, LR {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "                    avg_loss = 0\n",
        "\n",
        "                # Validation\n",
        "                if step % val_steps == 0:\n",
        "                    acc, cost, fpr, fnr = eval_loop_whisper(model, valloader)\n",
        "                    print(f\"Eval @ step {step}: ACC {acc:.2f}% AvgCost {cost:.4f}, AvgFPR {fpr:.4f}, AvgFNR {fnr:.4f}\")\n",
        "                    model.train()\n",
        "\n",
        "                step += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in training step {step}: {e}\")\n",
        "                # Skip this batch and continue\n",
        "                step += 1\n",
        "                continue\n",
        "\n",
        "    return model\n",
        "\n",
        "# Modified submission writer\n",
        "def submission_writer_whisper(model, loader, logits_file='logits.tsv', preds_file='predictions.tsv'):\n",
        "    \"\"\"\n",
        "    Generate submission files for Whisper + ARBERT model\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Clear existing files\n",
        "    open(logits_file, 'w').close()\n",
        "    open(preds_file, 'w').close()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Generating submission\"):\n",
        "            wavs, _, labels = batch\n",
        "\n",
        "            # Forward pass\n",
        "            o = model(wavs, training=False)\n",
        "\n",
        "            # Write results\n",
        "            write_logits(o[0].cpu(), logits_file)\n",
        "            write_preds(o[2].cpu(), preds_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298,
          "referenced_widgets": [
            "2d6ba7ce4de04c51af780283789fa24e",
            "f02a38a13cfa4633b29d52a4f9ffce17",
            "5821be7577c04207907f4d5f211fd5eb",
            "90111218ea1848cdbfd979a781711338",
            "1aa7e00ba14e4a6c963e00689ed568cf",
            "753c47fecaf8432bbba3e1f837a37a3d",
            "2b9e551904544b6fba826b893a30c49e",
            "132e0828dc324ef8be28d6f5ba212305",
            "ba19e43cba614006bc4e02d6dd04dc75",
            "71fb67fed262481abd78056390d74375",
            "6fa76991fed4446ca1ccd14b87d69c59",
            "263ac938df0144d1b24bf7be40d5d5e8",
            "7c81e10944f345629f261a502234ade4",
            "f98b081f82b54d7580b58380412d9832",
            "4c12b077e2a64e509cb19c99a8f7e374",
            "218e9a1c23704ba4afc9a2dcd2af7036",
            "59b94250c5944af089c580361f2f37c0",
            "333a928067f541918d699477868c0648",
            "53946334e63e4a659d0caa3b1dc6ce09",
            "4a4e4042db1b40b68c85b89e3c90f9bd",
            "6237a29e4db74192b20eb0ed900bc8c5",
            "02da6ec0202244e2be1b00aded57bc2c",
            "5d9beca262bc437f8f6411258af9df1a",
            "9c82e372e03149cd8a241872ab026f53",
            "4ca1e9b90bf94751a883211a12889b70",
            "03ada9bd5680485781bddb1e96345f65",
            "4e2ff1dfb05145309dfdc7aa252da600",
            "6671933436444f37b2f0d71c2be45043",
            "8f0540f6976a47d3883d3827da4090d9",
            "caffb2c8ea40430bbe7747c9319030b2",
            "82d3f4e5537941b294d01e2444b75116",
            "bb0c93a9dac044bf8a73e22fe5626a63",
            "8e03d052f15640cda21d2e7fb64e5692",
            "5731738fbf0c4137bdf92432805c6ec3",
            "ac5c2eb398b44973b0f7724b458660b5",
            "6acfb216eabd4e3694acbee7a4cd007e",
            "5c7d64bdbe3f4108bd697a48f6c529ff",
            "50fb3d79276e4bf6a98b9b3f6460bcff",
            "13d203fd673348479b3b09590025bbae",
            "7bdbeb7c9f03401fa5768b31419b60d8",
            "4ea2e7fb71d146969294166d2a461bc5",
            "f3b340d0551a4813a9ad0c2d1b63e50c",
            "e023cf5b88a84524a8759658430e2fff",
            "f390e472698f473c9e31d085b0d18974",
            "3ee9afb40ede4a3bb586ba752ae624d8",
            "d08177aea25548658b5d363894fd3bed",
            "318530aa3625434a8ca1cbd435319130",
            "db6c9c1fcfb749b59a18ff3371cc12ea",
            "b84c8ca565e14f4c87b1e44eb8300d80",
            "d6ad43196a834b85a9de60ad832960b2",
            "ba267287097e428a96b40bf3dcd46dd8",
            "37d7d0e0eb404e719a9d518a9eab20cb",
            "142a500185784084aa28e2b3289760c8",
            "2d0b364de1da4769b993e414f9fb5fa7",
            "e65af9d23ce04443ad11171618318ff4"
          ]
        },
        "executionInfo": {
          "elapsed": 310282,
          "status": "ok",
          "timestamp": 1752088073465,
          "user": {
            "displayName": "MD.RAFIUL BISWAS",
            "userId": "15801257354586832441"
          },
          "user_tz": -180
        },
        "id": "ldgHctbEgKum",
        "outputId": "cbe8d702-7923-4c7c-c2f7-afcc4220394f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Whisper model: large-v3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.88G/2.88G [04:26<00:00, 11.6MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading text model: UBC-NLP/MARBERT\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d6ba7ce4de04c51af780283789fa24e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "263ac938df0144d1b24bf7be40d5d5e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d9beca262bc437f8f6411258af9df1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5731738fbf0c4137bdf92432805c6ec3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ee9afb40ede4a3bb586ba752ae624d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created new classifier: 768 -> 8\n",
            "Frozen Whisper parameters: 1,541,570,560\n",
            "Frozen text encoder parameters: 162,841,344\n",
            "Trainable classifier parameters: 6,152\n"
          ]
        }
      ],
      "source": [
        "model = create_whisper_arbert_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9wDb3y-gNcy"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(ds['train'], shuffle=True, collate_fn=col_fun_whisper, batch_size=8)  # Can use larger batch size now\n",
        "valloader = DataLoader(ds['validation'], shuffle=False, collate_fn=col_fun_whisper, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAQrAPtegx07"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "9697efcb6d62430bbf18dbfc7ead3593",
            "1d3999f0285f464c998afc1a27dc39b6",
            "6ba453c0616d4e87bf3fb1ce99bfcb35",
            "eaf406c2d7d74b1d924b21156a833168",
            "e78433d1332a4bbc81af05513183b2ea",
            "69b7320c29c34eb19de9b6aab01a4c32",
            "2219913688854df8aaf6cb9115dc75ec",
            "bb73a435aabe491481c7f2b29e7d6592",
            "b33c9a4759d8407a8c9ef7b9fccdf4f0",
            "edd78561abf54818948d4cc6ea9044a0",
            "ad4059e29bda4ab09e297c2196c570ba",
            "ddab31ab029644b3a4a8aa9e7bba10c9",
            "d2b194ac2afb4fb59f8968fc8ab2fd64",
            "48e67888ebd14efcab843da22a721b55",
            "92fa92b7258e462288303b2e17acb2be",
            "6896696ea0384082a4ed6f92c31a2522",
            "ce192450ed5e4ed3aaf83cba22e9d77d",
            "de7116244ce749e78cd2f87cb85087e6",
            "14157cade22047d792b8c51a9ec003a9",
            "8f837d9f5c7e4117b98f7cfeb1925163",
            "09ff365dd5564bbe901ea9ae0591d8fe",
            "b71affcb0e024517b0fca835540d54af"
          ]
        },
        "id": "MgbkJJ1AgPPH",
        "outputId": "2a5f9b1a-9916-4004-eefa-198d043302b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "trainable params: 6152 || all params: 1704418056 || trainable%: 0.00\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9697efcb6d62430bbf18dbfc7ead3593",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Step 1:   0%|          | 0/1613 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100: Loss 2.2058, LR 8.00e-06\n",
            "Step 200: Loss 2.1846, LR 1.40e-05\n",
            "Step 300: Loss 2.1355, LR 2.00e-05\n",
            "Step 400: Loss 2.1155, LR 2.00e-05\n",
            "Step 500: Loss 2.1033, LR 2.00e-05\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddab31ab029644b3a4a8aa9e7bba10c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3175 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trained_model = train_whisper_arbert_model(model, trainloader, valloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR-gsoQPgRmK"
      },
      "outputs": [],
      "source": [
        "acc, cost, fpr, fnr = eval_loop_whisper(trained_model, valloader)\n",
        "print(f\"Final Results: ACC {acc:.2f}% AvgCost {cost:.4f}, FPR {fpr:.4f}, FNR {fnr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe6viBSjg5PI"
      },
      "outputs": [],
      "source": [
        "# Generate submission:\n",
        "submission_writer_whisper(trained_model, valloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEe9pkHdeqHB"
      },
      "outputs": [],
      "source": [
        "# Usage example:\n",
        "\"\"\"\n",
        "# Replace the baseline model creation with:\n",
        "model = create_whisper_arbert_model()\n",
        "\n",
        "# Use the new collate function:\n",
        "trainloader = DataLoader(ds['train'], shuffle=True, collate_fn=col_fun_whisper, batch_size=4)  # Can use larger batch size now\n",
        "valloader = DataLoader(ds['validation'], shuffle=False, collate_fn=col_fun_whisper, batch_size=4)\n",
        "\n",
        "# Train the model:\n",
        "trained_model = train_whisper_arbert_model(model, trainloader, valloader, device)\n",
        "\n",
        "# Evaluate:\n",
        "acc, cost, fpr, fnr = eval_loop_whisper(trained_model, valloader)\n",
        "print(f\"Final Results: ACC {acc:.2f}% AvgCost {cost:.4f}, FPR {fpr:.4f}, FNR {fnr:.4f}\")\n",
        "\n",
        "# Generate submission:\n",
        "submission_writer_whisper(trained_model, valloader)\n",
        "\"\"\"\n",
        "\n",
        "# Helper function to check trainable parameters (enhanced like SpeechBrain)\n",
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Print trainable parameters with detailed breakdown\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "\n",
        "    print(\"\\n=== MODEL PARAMETER BREAKDOWN ===\")\n",
        "    for name, param in model.named_parameters():\n",
        "        param_count = param.numel()\n",
        "        all_param += param_count\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param_count\n",
        "            print(f\"\u2713 TRAINABLE: {name:40} - {param_count:>10,} params\")\n",
        "        else:\n",
        "            print(f\"\u2717 FROZEN:    {name:40} - {param_count:>10,} params\")\n",
        "\n",
        "    print(f\"\\n=== SUMMARY ===\")\n",
        "    print(f\"Total parameters:     {all_param:>15,}\")\n",
        "    print(f\"Trainable parameters: {trainable_params:>15,}\")\n",
        "    print(f\"Frozen parameters:    {all_param - trainable_params:>15,}\")\n",
        "    print(f\"Trainable percentage: {100 * trainable_params / all_param:>14.2f}%\")\n",
        "    print(f\"Model size:           {all_param/1e6:>14.1f}M parameters\")\n",
        "    print(f\"Training only:        {trainable_params/1e6:>14.1f}M parameters\")\n",
        "\n",
        "    # Memory efficiency info\n",
        "    trainable_memory_mb = trainable_params * 4 / (1024 * 1024)  # Assuming float32\n",
        "    print(f\"Trainable memory:     {trainable_memory_mb:>14.1f}MB\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "# Keep all the original cost calculation functions (llr, compute_actual_cost, compute_ave_cost)\n",
        "# and submission writing functions (write_logits, write_preds) as they are unchanged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-wUmM8SXxNw"
      },
      "outputs": [],
      "source": [
        "!zip submission.zip logits.tsv predictions.tsv"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1QvAod7rtMTsh_DNjQHCEOCvvw4cYqbKX",
      "authorship_tag": "ABX9TyMB0EcJ7tWfpzJjypTulHU/"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}